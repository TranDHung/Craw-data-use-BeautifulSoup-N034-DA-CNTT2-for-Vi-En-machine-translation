{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frZRIeNnHuoT",
        "outputId": "8df5f5d1-ab8a-4161-920f-c4bd917a5673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==3.1.0a0)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.7.22)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16352 sha256=7a222b701d5e7450748f749817d77bb3d50c86d81cb8f271d31edb13cb363315\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/5d/3c/8477d0af4ca2b8b1308812c09f1930863caeebc762fe265a95\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.29.36)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2023.6.3)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.1)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.2/286.2 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.23.5)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.7.1)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (16.0.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11291797 sha256=e0c7c8028f8cba0ecef4f68c9b94cb9d6c543d28530ee9b355a8e0920a134a6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=164edc4891e1c63596e01dc374782e61caa710ae91d44b87b8b40c491caad3f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.8.1 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans==3.1.0a0\n",
        "!pip install fairseq\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Mount from drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jab15jVWITcp",
        "outputId": "6169b2be-d895-40f0-843b-5ed51fd217f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google/sentencepiece.git\n",
        "!mkdir sentencepiece/build\n",
        "!cd sentencepiece/build && cmake ..\n",
        "!cd sentencepiece/build && make -j $(nproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnT-CohnH-eK",
        "outputId": "36e1d530-2fe2-4ebc-961f-c5d0674a39f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 4823, done.\u001b[K\n",
            "remote: Counting objects: 100% (1886/1886), done.\u001b[K\n",
            "remote: Compressing objects: 100% (212/212), done.\u001b[K\n",
            "remote: Total 4823 (delta 1701), reused 1674 (delta 1674), pack-reused 2937\u001b[K\n",
            "Receiving objects: 100% (4823/4823), 26.68 MiB | 16.45 MiB/s, done.\n",
            "Resolving deltas: 100% (3338/3338), done.\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:15 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- VERSION: 0.2.00\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Not Found TCMalloc: TCMALLOC_LIB-NOTFOUND\n",
            "-- Configuring done (0.7s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/sentencepiece/build\n",
            "[  0%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/usr/include/string.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/port.h:39\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/macros.h:34\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/common.h:46\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/message_lite.h:45\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:36\u001b[m\u001b[K:\n",
            "In function ‘\u001b[01m\u001b[Kvoid* memcpy(void*, const void*, size_t)\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[Kgoogle::protobuf::uint8* google::protobuf::io::EpsCopyOutputStream::WriteRaw(const void*, int, google::protobuf::uint8*)\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/io/coded_stream.h:699:16\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvirtual google::protobuf::uint8* google::protobuf::internal::ImplicitWeakMessage::_InternalSerialize(google::protobuf::uint8*, google::protobuf::io::EpsCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/implicit_weak_message.h:85:28\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kbool google::protobuf::MessageLite::SerializePartialToZeroCopyStream(google::protobuf::io::ZeroCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:419:30\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:29:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* __builtin___memcpy_chk(void*, const void*, long unsigned int, long unsigned int)\u001b[m\u001b[K’ specified size between 18446744071562067968 and 18446744073709551615 exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wstringop-overflow=\u0007-Wstringop-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |   return \u001b[01;35m\u001b[K__builtin___memcpy_chk (__dest, __src, __len,\u001b[m\u001b[K\n",
            "      |          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   30 | \u001b[01;35m\u001b[K                                 __glibc_objsize0 (__dest))\u001b[m\u001b[K;\n",
            "      |                                  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/include/string.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/port.h:39\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/macros.h:34\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/common.h:46\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/message_lite.h:45\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:36\u001b[m\u001b[K:\n",
            "In function ‘\u001b[01m\u001b[Kvoid* memcpy(void*, const void*, size_t)\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[Kgoogle::protobuf::uint8* google::protobuf::io::EpsCopyOutputStream::WriteRaw(const void*, int, google::protobuf::uint8*)\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/io/coded_stream.h:699:16\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvirtual google::protobuf::uint8* google::protobuf::internal::ImplicitWeakMessage::_InternalSerialize(google::protobuf::uint8*, google::protobuf::io::EpsCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/implicit_weak_message.h:85:28\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kbool google::protobuf::MessageLite::SerializePartialToZeroCopyStream(google::protobuf::io::ZeroCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:419:30\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:29:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* __builtin___memcpy_chk(void*, const void*, long unsigned int, long unsigned int)\u001b[m\u001b[K’ specified size between 18446744071562067968 and 18446744073709551615 exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wstringop-overflow=\u0007-Wstringop-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |   return \u001b[01;35m\u001b[K__builtin___memcpy_chk (__dest, __src, __len,\u001b[m\u001b[K\n",
            "      |          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   30 | \u001b[01;35m\u001b[K                                 __glibc_objsize0 (__dest))\u001b[m\u001b[K;\n",
            "      |                                  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[ 24%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/parse_context.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/parse_context.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/char_model.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/char_model.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/error.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/error.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/filesystem.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/filesystem.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/model_factory.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/model_factory.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/model_interface.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/model_interface.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/normalizer.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/normalizer.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/util.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/util.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/word_model.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/word_model.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library libsentencepiece.a\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX shared library libsentencepiece.so\u001b[0m\n",
            "[ 71%] Built target sentencepiece\n",
            "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/builder.cc.o\u001b[0m\n",
            "[ 72%] Built target sentencepiece-static\n",
            "[ 73%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_encode.dir/spm_encode_main.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32m\u001b[1mLinking CXX executable spm_encode\u001b[0m\n",
            "[ 74%] Built target spm_encode\n",
            "[ 75%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_decode.dir/spm_decode_main.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/unicode_script.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable spm_decode\u001b[0m\n",
            "[ 76%] Built target spm_decode\n",
            "[ 77%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_export_vocab.dir/spm_export_vocab_main.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable spm_export_vocab\u001b[0m\n",
            "[ 78%] Built target spm_export_vocab\n",
            "[ 79%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/builder.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/unicode_script.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX static library libsentencepiece_train.a\u001b[0m\n",
            "[ 93%] Built target sentencepiece_train-static\n",
            "[ 94%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX shared library libsentencepiece_train.so\u001b[0m\n",
            "[ 96%] Built target sentencepiece_train\n",
            "[ 97%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_train.dir/spm_train_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_normalize.dir/spm_normalize_main.cc.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable spm_normalize\u001b[0m\n",
            "[ 99%] Built target spm_normalize\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable spm_train\u001b[0m\n",
            "[100%] Built target spm_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "The test dataset using is IWSLT'15 English-Vietnamese which is available at https://nlp.stanford.edu/projects/nmt/"
      ],
      "metadata": {
        "id": "jE-4ITiUi8B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download test data\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.vi\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuLIdpeHH8tL",
        "outputId": "7b5f3a38-0769-4c2b-fe99-014f1092699c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-07 13:02:43--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140250 (137K) [text/plain]\n",
            "Saving to: ‘tst2012.en’\n",
            "\n",
            "tst2012.en          100%[===================>] 136.96K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-07 13:02:43 (1.41 MB/s) - ‘tst2012.en’ saved [140250/140250]\n",
            "\n",
            "--2023-09-07 13:02:43--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 188396 (184K) [text/plain]\n",
            "Saving to: ‘tst2012.vi’\n",
            "\n",
            "tst2012.vi          100%[===================>] 183.98K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-07 13:02:44 (1.88 MB/s) - ‘tst2012.vi’ saved [188396/188396]\n",
            "\n",
            "--2023-09-07 13:02:44--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132264 (129K) [text/plain]\n",
            "Saving to: ‘tst2013.en’\n",
            "\n",
            "tst2013.en          100%[===================>] 129.16K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-07 13:02:44 (1.31 MB/s) - ‘tst2013.en’ saved [132264/132264]\n",
            "\n",
            "--2023-09-07 13:02:44--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 183855 (180K) [text/plain]\n",
            "Saving to: ‘tst2013.vi’\n",
            "\n",
            "tst2013.vi          100%[===================>] 179.55K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-07 13:02:44 (1.32 MB/s) - ‘tst2013.vi’ saved [183855/183855]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate test set with googleTrans"
      ],
      "metadata": {
        "id": "6bfAfmPtmERW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "from tqdm import tqdm\n",
        "import fileinput\n",
        "\n",
        "#define a translate function\n",
        "def translate_GoogleTrans(vi_lst, ver):\n",
        "  translator = Translator()\n",
        "  with open(\"googleTrans_\" + str(ver) +\".en\", \"w\") as file_trans:\n",
        "    for vi in tqdm(vi_lst):\n",
        "      result = translator.translate(vi, src='vi', dest='en')\n",
        "      print(result.text, file=file_trans)"
      ],
      "metadata": {
        "id": "7eN0dsCfkPRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate vi to en on testset tst2012.vi and tst2013.vi using GoogleTrans"
      ],
      "metadata": {
        "id": "ImJApqiRw67j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read test set 2012 and translate\n",
        "vi_2012 = [vi[:-1] for vi in open('/content/tst2012.vi','r')]\n",
        "translate_GoogleTrans(vi_2012, 2012)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5HaXQDHn8TB",
        "outputId": "31f9f454-9dd8-443c-b4c0-0d694ce722a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1553/1553 [00:49<00:00, 31.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 10 translated sentence from vi - en on tst2012\n",
        "!head -n 10 googleTrans_2012.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acE6Uqhjzfbk",
        "outputId": "c5d32556-7c97-45ab-a1e7-5a3f6f47cef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How can I present in 10 minutes about the bond that binds women through three generations, about how those amazingly strong bonds have gripped the life of a four-year-old girl? curled up with her little sister , with her mother and grandmother during the five days and nights on a small boat floating in the East Sea more than 30 years ago , the bonds that held her life and never now leave -- that girl now lives in San Francisco and is talking to you today ?\n",
            "This story is not over.\n",
            "It is a jigsaw puzzle that is still being stacked .\n",
            "Let me tell you about some of the pieces.\n",
            "Imagine the first piece: a man who burned his career for the rest of his life.\n",
            "He was a poet and playwright, a man whose whole life was precarious with the only hope that his country would be independent and free.\n",
            "Imagine him, a communist entering Saigon, facing the fact that his whole life was wasted.\n",
            "Words, which have been his companion for many years, are now mocking him.\n",
            "He retreated into silence.\n",
            "He died, knocked down by history.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read test set 2013 and translate\n",
        "vi_2013 = [vi[:-1] for vi in open('/content/tst2013.vi','r')]\n",
        "translate_GoogleTrans(vi_2013, 2013)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e89-wKDZo1fp",
        "outputId": "43da4cc2-6de0-4b98-ed5b-978db8fa70e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1268/1268 [00:44<00:00, 28.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 10 translated sentence from vi - en on tst2013\n",
        "!head -n 10 googleTrans_2013.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eYFcDH0zpBr",
        "outputId": "462f2839-bfab-492a-cf1c-612c75c8c5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When I was little, I thought North Korea was the best country in the world and I used to sing \"We have nothing to be jealous of.\"\n",
            "I was very proud of my country.\n",
            "At school, we spend a lot of time learning about the life of president Kim II-Sung, but we don't learn much about the outside world, except that the United States, Korea and Japan are our enemies. I .\n",
            "Although I used to wonder what the outside world was like, I still thought that I would live my whole life in North Korea, until everything suddenly changed.\n",
            "When I was 7 years old, I witnessed people being shot publicly for the first time in my life, but I still think my life here is completely normal.\n",
            "My family is not poor, and I myself have never suffered from hunger.\n",
            "But one day in 1995 , my mother brought home a letter from a sister in her workplace .\n",
            "In it is written: When you read these lines, my whole family of 5 is no longer in this world, because my whole family has had nothing to eat for two weeks.\n",
            "We were all lying on the floor, and our bodies were so weak that it felt like death was approaching.\n",
            "I was socked .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate bleu score on 2 translated set"
      ],
      "metadata": {
        "id": "x6Pf49E2xPkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate on tst2012\n",
        "!sacrebleu -tok 'none' -s 'none' tst2012.en < googleTrans_2012.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5L2lY64v3Zh",
        "outputId": "60aa8b4b-06d8-43b2-ef8c-5de4e3bc459c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sacreBLEU: That's 100 lines that end in a tokenized period ('.')\n",
            "sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 21.7,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.3.1\",\n",
            " \"verbose_score\": \"56.6/31.8/19.5/12.3 (BP = 0.845 ratio = 0.856 hyp_len = 23956 ref_len = 27983)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"none\",\n",
            " \"smooth\": \"none\",\n",
            " \"version\": \"2.3.1\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate on tst2013\n",
        "!sacrebleu -tok 'none' -s 'none' tst2013.en < googleTrans_2013.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woOTWhB5wykD",
        "outputId": "ac915dcd-1b1b-40c8-f282-545217e97523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sacreBLEU: That's 100 lines that end in a tokenized period ('.')\n",
            "sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 25.8,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.3.1\",\n",
            " \"verbose_score\": \"60.9/36.4/23.3/15.6 (BP = 0.860 ratio = 0.869 hyp_len = 23217 ref_len = 26728)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"none\",\n",
            " \"smooth\": \"none\",\n",
            " \"version\": \"2.3.1\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate test set with our model"
      ],
      "metadata": {
        "id": "qANAHV7Eyz48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SPM encoding\n",
        "%env SPM=/content/sentencepiece/build/src\n",
        "!mkdir tokenized\n",
        "!$SPM/spm_encode --model=\"drive/MyDrive/sentencepiece.bpe.model\" --output_format=piece < \"tst2012.vi\" > tokenized/tst2012.spm.vi\n",
        "!$SPM/spm_encode --model=\"drive/MyDrive/sentencepiece.bpe.model\" --output_format=piece < \"tst2013.vi\" > tokenized/tst2013.spm.vi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAAvXQ48y18j",
        "outputId": "ac1d29ac-d77a-43cb-a50b-00ecdaa51813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SPM=/content/sentencepiece/build/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing for tst2012\n",
        "!fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --source-lang vi --target-lang en \\\n",
        "    --joined-dictionary \\\n",
        "    --srcdict drive/MyDrive/checkpointbest/dict.vi.txt \\\n",
        "    --testpref tokenized/tst2012.spm \\\n",
        "    --destdir data-bin-2012 \\\n",
        "    --workers 70;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV7eU8Ib0ZsE",
        "outputId": "95fc90ae-83a4-4605-f392-00929182e6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-07 13:30:26.905395: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-07 13:30:27.777133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-09-07 13:30:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-09-07 13:30:29 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='vi', target_lang='en', trainpref=None, validpref=None, testpref='tokenized/tst2012.spm', align_suffix=None, destdir='data-bin-2012', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='drive/MyDrive/checkpointbest/dict.vi.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=True, padding_factor=8, workers=70, dict_only=False)\n",
            "2023-09-07 13:30:29 | INFO | fairseq_cli.preprocess | [vi] Dictionary: 41630 types\n",
            "2023-09-07 13:30:32 | INFO | fairseq_cli.preprocess | [vi] tokenized/tst2012.spm.vi: 1553 sents, 40272 tokens, 0.00745% replaced (by <unk>)\n",
            "2023-09-07 13:30:32 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin-2012\n",
            "/bin/bash: line 3: \\: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing for tst2013\n",
        "!fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --source-lang vi --target-lang en \\\n",
        "    --joined-dictionary \\\n",
        "    --srcdict drive/MyDrive/checkpointbest/dict.vi.txt \\\n",
        "    --testpref tokenized/tst2013.spm \\\n",
        "    --destdir data-bin-2013 \\\n",
        "    --workers 70;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP3wA2fQ1qQ2",
        "outputId": "b2958726-aef9-4f37-c62f-2e8c43cabf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-07 13:31:04.003386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-07 13:31:05.329614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-09-07 13:31:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-09-07 13:31:07 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='vi', target_lang='en', trainpref=None, validpref=None, testpref='tokenized/tst2013.spm', align_suffix=None, destdir='data-bin-2013', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='drive/MyDrive/checkpointbest/dict.vi.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=True, padding_factor=8, workers=70, dict_only=False)\n",
            "2023-09-07 13:31:07 | INFO | fairseq_cli.preprocess | [vi] Dictionary: 41630 types\n",
            "2023-09-07 13:31:11 | INFO | fairseq_cli.preprocess | [vi] tokenized/tst2013.spm.vi: 1268 sents, 39895 tokens, 0.0226% replaced (by <unk>)\n",
            "2023-09-07 13:31:11 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin-2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy en dict to 2012 and 2013 data-bin-dir\n",
        "!cp drive/MyDrive/checkpointbest/dict.en.txt data-bin-2012/\n",
        "!cp drive/MyDrive/checkpointbest/dict.en.txt data-bin-2013/"
      ],
      "metadata": {
        "id": "BFTcJ4MC3FCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate on 2012 test set\n",
        "!fairseq-generate \\\n",
        "    data-bin-2012 \\\n",
        "  --path drive/MyDrive/checkpointbest/checkpoint_best.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --source-lang vi --target-lang en \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model drive/MyDrive/sentencepiece.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --beam 5 --nbest 1 \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > result_2012.out\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUoN-iex1zFM",
        "outputId": "e5d2c032-cb72-4d88-eb23-276233ce6903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-07 13:38:09.249104: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-07 13:38:10.187828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-09-07 13:38:12 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-09-07 13:38:16 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'drive/MyDrive/checkpointbest/checkpoint_best.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': True, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe='sentencepiece', optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation_from_pretrained_bart', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=32, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=32, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='drive/MyDrive/checkpointbest/checkpoint_best.pt', post_process='sentencepiece', quiet=False, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, unkpen=0, replace_unk=None, sacrebleu=True, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='data-bin-2012', source_lang='vi', target_lang='en', load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', prepend_bos=False, sentencepiece_model='drive/MyDrive/sentencepiece.bpe.model', sentencepiece_enable_sampling=False, sentencepiece_alpha=None, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, _name='translation_from_pretrained_bart'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'drive/MyDrive/sentencepiece.bpe.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-09-07 13:38:16 | INFO | fairseq.tasks.translation | [vi] dictionary: 41630 types\n",
            "2023-09-07 13:38:16 | INFO | fairseq.tasks.translation | [en] dictionary: 41630 types\n",
            "2023-09-07 13:38:16 | INFO | fairseq_cli.generate | loading model(s) from drive/MyDrive/checkpointbest/checkpoint_best.pt\n",
            "2023-09-07 13:39:51 | INFO | fairseq.data.data_utils | loaded 1,553 examples from: data-bin-2012/test.vi-en.vi\n",
            "2023-09-07 13:39:51 | INFO | fairseq.tasks.translation | data-bin-2012 test vi-en 1553 examples\n",
            "2023-09-07 13:41:13 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2023-09-07 13:41:13 | INFO | fairseq_cli.generate | Translated 1,553 sentences (38,467 tokens) in 64.7s (24.00 sentences/s, 594.38 tokens/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate on 2013 test set\n",
        "!fairseq-generate \\\n",
        "    data-bin-2013 \\\n",
        "  --path drive/MyDrive/checkpointbest/checkpoint_best.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --source-lang vi --target-lang en \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model drive/MyDrive/sentencepiece.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --beam 5 --nbest 1 \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > result_2013.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzcYiF2O3kE2",
        "outputId": "0e7089c8-5d06-4262-902c-13d3ec7a0de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-07 13:41:30.008175: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-07 13:41:31.562161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-09-07 13:41:34 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-09-07 13:41:36 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'drive/MyDrive/checkpointbest/checkpoint_best.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': True, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe='sentencepiece', optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation_from_pretrained_bart', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=32, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=32, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='drive/MyDrive/checkpointbest/checkpoint_best.pt', post_process='sentencepiece', quiet=False, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, unkpen=0, replace_unk=None, sacrebleu=True, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='data-bin-2013', source_lang='vi', target_lang='en', load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', prepend_bos=False, sentencepiece_model='drive/MyDrive/sentencepiece.bpe.model', sentencepiece_enable_sampling=False, sentencepiece_alpha=None, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, _name='translation_from_pretrained_bart'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'drive/MyDrive/sentencepiece.bpe.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-09-07 13:41:37 | INFO | fairseq.tasks.translation | [vi] dictionary: 41630 types\n",
            "2023-09-07 13:41:37 | INFO | fairseq.tasks.translation | [en] dictionary: 41630 types\n",
            "2023-09-07 13:41:37 | INFO | fairseq_cli.generate | loading model(s) from drive/MyDrive/checkpointbest/checkpoint_best.pt\n",
            "2023-09-07 13:42:17 | INFO | fairseq.data.data_utils | loaded 1,268 examples from: data-bin-2013/test.vi-en.vi\n",
            "2023-09-07 13:42:17 | INFO | fairseq.tasks.translation | data-bin-2013 test vi-en 1268 examples\n",
            "2023-09-07 13:43:39 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2023-09-07 13:43:39 | INFO | fairseq_cli.generate | Translated 1,268 sentences (36,990 tokens) in 65.9s (19.23 sentences/s, 561.04 tokens/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate bleu score on 2 translated set"
      ],
      "metadata": {
        "id": "SKtb2Eje4fdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate on tst2012\n",
        "!cat result_2012.out | grep -P \"^H\" | sort -V | cut -f 3- | sed 's/\\[en\\]//g' > vi_en_2012.hyp\n",
        "!sacrebleu -tok 'none' -s 'none' tst2012.en < vi_en_2012.hyp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoYkjGKx4KN-",
        "outputId": "91af6add-8b8a-4f55-eef2-a4578f7735c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sacreBLEU: That's 100 lines that end in a tokenized period ('.')\n",
            "sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 27.2,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.3.1\",\n",
            " \"verbose_score\": \"60.2/33.9/21.2/13.7 (BP = 0.981 ratio = 0.981 hyp_len = 27458 ref_len = 27983)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"none\",\n",
            " \"smooth\": \"none\",\n",
            " \"version\": \"2.3.1\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate on tst2013\n",
        "!cat result_2013.out | grep -P \"^H\" | sort -V | cut -f 3- | sed 's/\\[en\\]//g' > vi_en_2013.hyp\n",
        "!sacrebleu -tok 'none' -s 'none' tst2013.en < vi_en_2013.hyp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILG0o1oA4jFW",
        "outputId": "4c4c285d-f6e2-4f28-f56a-01794ba11189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sacreBLEU: That's 100 lines that end in a tokenized period ('.')\n",
            "sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 33.3,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.3.1\",\n",
            " \"verbose_score\": \"65.6/40.2/26.7/18.2 (BP = 0.990 ratio = 0.990 hyp_len = 26463 ref_len = 26728)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"none\",\n",
            " \"smooth\": \"none\",\n",
            " \"version\": \"2.3.1\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a comparision translated sentences between mBart, googleTrans, and the reference from test set"
      ],
      "metadata": {
        "id": "wMN8_WwU7t2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we got:\n",
        "\n",
        "- **21.7** BLEU socre by GoogleTrans and **27.2** by mBart on test set 2012\n",
        "\n",
        "- **25.8** BLEU score by GoogleTrans and **33.3** by mBart on test set 2013\n"
      ],
      "metadata": {
        "id": "9KnovuOz8e5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Compare on 2012 test set\n",
        "df_2012 = pd.DataFrame.from_dict(\n",
        "    {\n",
        "        'mBart': [line[:-1] for line in open('/content/vi_en_2012.hyp','r')],\n",
        "        'googleTrans': [line[:-1] for line in open('/content/googleTrans_2012.en','r')],\n",
        "        'reference' : [line[:-1] for line in open('/content/tst2012.en','r')]\n",
        "    }\n",
        ")\n",
        "df_2012.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "soQEMShU53B1",
        "outputId": "4f70739e-3482-49ab-c6c2-367a7e277b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                mBart  \\\n",
              "0   How can I present in 10 minutes the link wire ...   \n",
              "1                       This story isn &apos;t over .   \n",
              "2   It &apos;s a puzzle that &apos;s still being s...   \n",
              "3     Let me tell you guys about a couple of pieces .   \n",
              "4   Imagine the first piece : a man burning career...   \n",
              "5   He was a poet , a playwright , a person whose ...   \n",
              "6   Imagine him , a communist coming into Saigon ,...   \n",
              "7   The word , over so many years of being a compa...   \n",
              "8                         He retreated into silence .   \n",
              "9                   He died , overturned by history .   \n",
              "10                            He was my grandfather .   \n",
              "11                       I never met him in my life .   \n",
              "12  But our lives are much more than we store in o...   \n",
              "13  My grandmother never allowed me to forget his ...   \n",
              "14  My mission was not to let her life pass in hop...   \n",
              "15  The next piece of the picture is a boat in the...   \n",
              "16  My mother , Mai , was only 18 when her three l...   \n",
              "17  With her mother , her life hinged on the only ...   \n",
              "18  Mom never accepted that she wouldn &apos;t suc...   \n",
              "19  So after four years , a field of sky even clea...   \n",
              "\n",
              "                                          googleTrans  \\\n",
              "0   How can I present in 10 minutes about the bond...   \n",
              "1                             This story is not over.   \n",
              "2   It is a jigsaw puzzle that is still being stac...   \n",
              "3           Let me tell you about some of the pieces.   \n",
              "4   Imagine the first piece: a man who burned his ...   \n",
              "5   He was a poet and playwright, a man whose whol...   \n",
              "6   Imagine him, a communist entering Saigon, faci...   \n",
              "7   Words, which have been his companion for many ...   \n",
              "8                          He retreated into silence.   \n",
              "9                   He died, knocked down by history.   \n",
              "10                              He is my grandfather.   \n",
              "11                 I have never met him in real life.   \n",
              "12  But our life is much more than what we keep in...   \n",
              "13  My grandmother never allowed me to forget his ...   \n",
              "14  My job was not to let that life pass in vain, ...   \n",
              "15  The next piece of the picture is a boat in the...   \n",
              "16  My mother , Mai , was 18 years old when her fa...   \n",
              "17  For her, life boils down to a single mission: ...   \n",
              "18        I can never accept that I will not succeed.   \n",
              "19  So, after four years, in a paradise more exten...   \n",
              "\n",
              "                                            reference  \n",
              "0   How can I speak in 10 minutes about the bonds ...  \n",
              "1                      This is not a finished story .  \n",
              "2    It is a jigsaw puzzle still being put together .  \n",
              "3          Let me tell you about some of the pieces .  \n",
              "4   Imagine the first piece : a man burning his li...  \n",
              "5   He is a poet , a playwright , a man whose whol...  \n",
              "6   Imagine him as the communists enter Saigon , c...  \n",
              "7   Words , for so long his friends , now mocked h...  \n",
              "8                         He retreated into silence .  \n",
              "9                         He died broken by history .  \n",
              "10                             He is my grandfather .  \n",
              "11                    I never knew him in real life .  \n",
              "12    But our lives are much more than our memories .  \n",
              "13      My grandmother never let me forget his life .  \n",
              "14  My duty was not to allow it to have been in va...  \n",
              "15  The next piece of the jigsaw is of a boat in t...  \n",
              "16  My mother , Mai , was 18 when her father died ...  \n",
              "17  For her , life had distilled itself into one t...  \n",
              "18  It was inconceivable to her that she would not...  \n",
              "19  So after a four-year saga that defies fiction ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e85011c6-aa21-492e-ad29-c788417302fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mBart</th>\n",
              "      <th>googleTrans</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I present in 10 minutes the link wire ...</td>\n",
              "      <td>How can I present in 10 minutes about the bond...</td>\n",
              "      <td>How can I speak in 10 minutes about the bonds ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This story isn &amp;apos;t over .</td>\n",
              "      <td>This story is not over.</td>\n",
              "      <td>This is not a finished story .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It &amp;apos;s a puzzle that &amp;apos;s still being s...</td>\n",
              "      <td>It is a jigsaw puzzle that is still being stac...</td>\n",
              "      <td>It is a jigsaw puzzle still being put together .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Let me tell you guys about a couple of pieces .</td>\n",
              "      <td>Let me tell you about some of the pieces.</td>\n",
              "      <td>Let me tell you about some of the pieces .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Imagine the first piece : a man burning career...</td>\n",
              "      <td>Imagine the first piece: a man who burned his ...</td>\n",
              "      <td>Imagine the first piece : a man burning his li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>He was a poet , a playwright , a person whose ...</td>\n",
              "      <td>He was a poet and playwright, a man whose whol...</td>\n",
              "      <td>He is a poet , a playwright , a man whose whol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Imagine him , a communist coming into Saigon ,...</td>\n",
              "      <td>Imagine him, a communist entering Saigon, faci...</td>\n",
              "      <td>Imagine him as the communists enter Saigon , c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The word , over so many years of being a compa...</td>\n",
              "      <td>Words, which have been his companion for many ...</td>\n",
              "      <td>Words , for so long his friends , now mocked h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>He retreated into silence .</td>\n",
              "      <td>He retreated into silence.</td>\n",
              "      <td>He retreated into silence .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>He died , overturned by history .</td>\n",
              "      <td>He died, knocked down by history.</td>\n",
              "      <td>He died broken by history .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>He was my grandfather .</td>\n",
              "      <td>He is my grandfather.</td>\n",
              "      <td>He is my grandfather .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I never met him in my life .</td>\n",
              "      <td>I have never met him in real life.</td>\n",
              "      <td>I never knew him in real life .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>But our lives are much more than we store in o...</td>\n",
              "      <td>But our life is much more than what we keep in...</td>\n",
              "      <td>But our lives are much more than our memories .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>My grandmother never allowed me to forget his ...</td>\n",
              "      <td>My grandmother never allowed me to forget his ...</td>\n",
              "      <td>My grandmother never let me forget his life .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>My mission was not to let her life pass in hop...</td>\n",
              "      <td>My job was not to let that life pass in vain, ...</td>\n",
              "      <td>My duty was not to allow it to have been in va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The next piece of the picture is a boat in the...</td>\n",
              "      <td>The next piece of the picture is a boat in the...</td>\n",
              "      <td>The next piece of the jigsaw is of a boat in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>My mother , Mai , was only 18 when her three l...</td>\n",
              "      <td>My mother , Mai , was 18 years old when her fa...</td>\n",
              "      <td>My mother , Mai , was 18 when her father died ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>With her mother , her life hinged on the only ...</td>\n",
              "      <td>For her, life boils down to a single mission: ...</td>\n",
              "      <td>For her , life had distilled itself into one t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Mom never accepted that she wouldn &amp;apos;t suc...</td>\n",
              "      <td>I can never accept that I will not succeed.</td>\n",
              "      <td>It was inconceivable to her that she would not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>So after four years , a field of sky even clea...</td>\n",
              "      <td>So, after four years, in a paradise more exten...</td>\n",
              "      <td>So after a four-year saga that defies fiction ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e85011c6-aa21-492e-ad29-c788417302fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e85011c6-aa21-492e-ad29-c788417302fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e85011c6-aa21-492e-ad29-c788417302fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f8a827c-1382-41dc-a286-155ed3bf904d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f8a827c-1382-41dc-a286-155ed3bf904d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f8a827c-1382-41dc-a286-155ed3bf904d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No charts were generated by quickchart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare on 2013 test set\n",
        "df_2013 = pd.DataFrame.from_dict(\n",
        "    {\n",
        "        'mBart': [line[:-1] for line in open('/content/vi_en_2013.hyp','r')],\n",
        "        'googleTrans': [line[:-1] for line in open('/content/googleTrans_2013.en','r')],\n",
        "        'reference' : [line[:-1] for line in open('/content/tst2013.en','r')]\n",
        "    }\n",
        ")\n",
        "df_2013.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lq2c4FBo8AC3",
        "outputId": "af0d59a8-d3af-4d7e-ed01-2b08b952b0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                mBart  \\\n",
              "0   When I was a kid , I thought North-North Korea...   \n",
              "1                      I was so proud of my country .   \n",
              "2   At school , we spent a lot of time learning ab...   \n",
              "3   Although I used to wonder not how the world wa...   \n",
              "4   When I got to 7 , I witnessed people openly fi...   \n",
              "5   My family was not poor , and I myself had neve...   \n",
              "6   But on one day in 1995 , my mother brought hom...   \n",
              "7   It reads : When she read these lines , then my...   \n",
              "8   All lying on the floor , and our bodies gettin...   \n",
              "9                                     I was shocked .   \n",
              "10  Because it was the first time I knew that my f...   \n",
              "11  Not long after that , as I passed a station , ...   \n",
              "12  On the platform of the station was the dead bo...   \n",
              "13  But there &apos;s no one to help them , becaus...   \n",
              "14  In the mid- &apos; 90s , North Korea experienc...   \n",
              "15  It caused over a million North Koreans to die ...   \n",
              "16  The power outages were happening more and more...   \n",
              "17  I was wondering all the time why they had elec...   \n",
              "18  This is a picture from a satellite of North Ko...   \n",
              "19  This is the Pearl River it &apos;s the natural...   \n",
              "20  It &apos;s possible to see that the river bed ...   \n",
              "21                          But so many people died .   \n",
              "22     And I saw their bodies floating in the river .   \n",
              "23  I can &apos;t say specifically how I fled Nort...   \n",
              "24  At that time , I just thought I was going to h...   \n",
              "25  chứ never could I imagine that I would have to...   \n",
              "26  In China , it &apos;s very difficult for a gir...   \n",
              "27  I hadn &apos;t imagined what it would be like ...   \n",
              "28  I have always lived in a constant fear that my...   \n",
              "29  One day , that nightmare came true , I was arr...   \n",
              "30  Somebody informed them that I was North Korean...   \n",
              "31  I was terrified , and it felt like my heart wa...   \n",
              "32  For if as they saw there was anything unnatura...   \n",
              "33  I thought my life coming here was ending , but...   \n",
              "34  After he finished asking , one of the two poli...   \n",
              "35               It &apos;s not North Korean . &quot;   \n",
              "36          And they released me . It was a miracle .   \n",
              "37  Some North Koreans in China went to foreign em...   \n",
              "38                      these girls were very lucky .   \n",
              "39  because despite being arrested , learning was ...   \n",
              "40         But these North Koreans are not so lucky .   \n",
              "41  Every year , there are countless North Koreans...   \n",
              "42  While I was very lucky that I was released , s...   \n",
              "43  The fact that North Koreans had to hide their ...   \n",
              "44  Even if they &apos;ve learned Chinese and foun...   \n",
              "45  That &apos;s why after 10 years of hiding my r...   \n",
              "46  It &apos;s much more difficult to settle down ...   \n",
              "47  Since in South Korea , English is incredibly i...   \n",
              "48  I also realized a huge gap between the South a...   \n",
              "49  We were all North Koreans , but became very di...   \n",
              "\n",
              "                                          googleTrans  \\\n",
              "0   When I was little, I thought North Korea was t...   \n",
              "1                     I was very proud of my country.   \n",
              "2   At school, we spend a lot of time learning abo...   \n",
              "3   Although I used to wonder what the outside wor...   \n",
              "4   When I was 7 years old, I witnessed people bei...   \n",
              "5   My family is not poor, and I myself have never...   \n",
              "6   But one day in 1995 , my mother brought home a...   \n",
              "7   In it is written: When you read these lines, m...   \n",
              "8   We were all lying on the floor, and our bodies...   \n",
              "9                                      I was socked .   \n",
              "10  For that was the first time I knew that my com...   \n",
              "11  Not long after, as I passed a train station, I...   \n",
              "12  On the station floor lay the dead body of a wo...   \n",
              "13  But there is no one to help them, because ever...   \n",
              "14  In the mid-1990s, North Korea experienced a se...   \n",
              "15  It caused more than a million Koreans to starv...   \n",
              "16  Power outages were becoming more and more freq...   \n",
              "17  I always wonder why they have electricity and ...   \n",
              "18  This is a satellite image of North Korea at ni...   \n",
              "19  This is the Yalu River, it is the natural bord...   \n",
              "20  It can be seen that the river bed is very narr...   \n",
              "21                          But a lot of people died.   \n",
              "22      And I saw their bodies floating in the river.   \n",
              "23  I cannot say specifically about how I escaped ...   \n",
              "24  At that time, I just thought that I would have...   \n",
              "25  but never could I have imagined that I would h...   \n",
              "26  In China, life as a little girl isolated from ...   \n",
              "27  I could not have imagined what it would be lik...   \n",
              "28  I live in constant fear that my identity will ...   \n",
              "29  One day, that nightmare came true, I was arres...   \n",
              "30  Someone told them I was North Korean, so they ...   \n",
              "31  I was so scared , and felt like my heart was a...   \n",
              "32  Because if they see anything unnatural , I wil...   \n",
              "33  I thought my life was coming to an end, but I ...   \n",
              "34  After questioning , one of the policemen said ...   \n",
              "35                          It is not North Korean. \"   \n",
              "36             And they let me go. That is a miracle.   \n",
              "37  Some North Koreans in China have gone to forei...   \n",
              "38                       These girls were very lucky.   \n",
              "39  because although he was arrested , he was fina...   \n",
              "40          But these North Koreans are not so lucky.   \n",
              "41  Every year, countless North Koreans are arrest...   \n",
              "42  While I was very fortunate to have been releas...   \n",
              "43  It is a tragedy that North Koreans have to hid...   \n",
              "44  Even if they learn Chinese and find a job, the...   \n",
              "45  That's why after 10 years of hiding my true id...   \n",
              "46  Settling in here is much more difficult than I...   \n",
              "47  Because in Korea, English is very important, s...   \n",
              "48  I also realize a huge gap between South and No...   \n",
              "49  We are both Koreans , but have become very dif...   \n",
              "\n",
              "                                            reference  \n",
              "0   When I was little , I thought my country was t...  \n",
              "1                              And I was very proud .  \n",
              "2   In school , we spent a lot of time studying th...  \n",
              "3   Although I often wondered about the outside wo...  \n",
              "4   When I was seven years old , I saw my first pu...  \n",
              "5   My family was not poor , and myself , I had ne...  \n",
              "6   But one day , in 1995 , my mom brought home a ...  \n",
              "7   It read , &quot; When you read this , all five...  \n",
              "8   We are lying on the floor together , and our b...  \n",
              "9                                  I was so shocked .  \n",
              "10  This was the first time I heard that people in...  \n",
              "11  Soon after , when I was walking past a train s...  \n",
              "12  A lifeless woman was lying on the ground , whi...  \n",
              "13  But nobody helped them , because they were so ...  \n",
              "14   A huge famine hit North Korea in the mid-1990s .  \n",
              "15  Ultimately , more than a million North Koreans...  \n",
              "16  Power outages also became more and more freque...  \n",
              "17  I always wondered why they had lights but we d...  \n",
              "18  This is a satellite picture showing North Kore...  \n",
              "19  This is the Amrok River , which serves as a pa...  \n",
              "20  As you can see , the river can be very narrow ...  \n",
              "21                                     But many die .  \n",
              "22  Sometimes , I saw dead bodies floating down th...  \n",
              "23  I can &apos;t reveal many details &#91; about ...  \n",
              "24  But I only thought that I would be separated f...  \n",
              "25  I could have never imagined that it would take...  \n",
              "26  In China , it was hard living as a young girl ...  \n",
              "27  I had no idea what life was going to be like a...  \n",
              "28  So I was living in constant fear that my ident...  \n",
              "29  One day , my worst nightmare came true , when ...  \n",
              "30  Someone had accused me of being North Korean ,...  \n",
              "31  I was so scared , I thought my heart was going...  \n",
              "32  If anything seemed unnatural , I could be impr...  \n",
              "33  I thought my life was over , but I managed to ...  \n",
              "34  After they finished questioning me , one offic...  \n",
              "35              She &apos;s not North Korean . &quot;  \n",
              "36            And they let me go . It was a miracle .  \n",
              "37  Some North Koreans in China seek asylum in for...  \n",
              "38                        These girls were so lucky .  \n",
              "39  Even though they were caught , they were event...  \n",
              "40            These North Koreans were not so lucky .  \n",
              "41  Every year , countless North Koreans are caugh...  \n",
              "42  Even though I was really fortunate to get out ...  \n",
              "43  It &apos;s tragic that North Koreans have to h...  \n",
              "44  Even after learning a new language and getting...  \n",
              "45  That &apos;s why , after 10 years of hiding my...  \n",
              "46  Settling down in South Korea was a lot more ch...  \n",
              "47  English was so important in South Korea , so I...  \n",
              "48  Also , I realized there was a wide gap between...  \n",
              "49  We are all Korean , but inside , we have becom...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2d8dedb-24b4-4334-8252-53be0c1a6cd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mBart</th>\n",
              "      <th>googleTrans</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When I was a kid , I thought North-North Korea...</td>\n",
              "      <td>When I was little, I thought North Korea was t...</td>\n",
              "      <td>When I was little , I thought my country was t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I was so proud of my country .</td>\n",
              "      <td>I was very proud of my country.</td>\n",
              "      <td>And I was very proud .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At school , we spent a lot of time learning ab...</td>\n",
              "      <td>At school, we spend a lot of time learning abo...</td>\n",
              "      <td>In school , we spent a lot of time studying th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Although I used to wonder not how the world wa...</td>\n",
              "      <td>Although I used to wonder what the outside wor...</td>\n",
              "      <td>Although I often wondered about the outside wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When I got to 7 , I witnessed people openly fi...</td>\n",
              "      <td>When I was 7 years old, I witnessed people bei...</td>\n",
              "      <td>When I was seven years old , I saw my first pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>My family was not poor , and I myself had neve...</td>\n",
              "      <td>My family is not poor, and I myself have never...</td>\n",
              "      <td>My family was not poor , and myself , I had ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>But on one day in 1995 , my mother brought hom...</td>\n",
              "      <td>But one day in 1995 , my mother brought home a...</td>\n",
              "      <td>But one day , in 1995 , my mom brought home a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>It reads : When she read these lines , then my...</td>\n",
              "      <td>In it is written: When you read these lines, m...</td>\n",
              "      <td>It read , &amp;quot; When you read this , all five...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>All lying on the floor , and our bodies gettin...</td>\n",
              "      <td>We were all lying on the floor, and our bodies...</td>\n",
              "      <td>We are lying on the floor together , and our b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I was shocked .</td>\n",
              "      <td>I was socked .</td>\n",
              "      <td>I was so shocked .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Because it was the first time I knew that my f...</td>\n",
              "      <td>For that was the first time I knew that my com...</td>\n",
              "      <td>This was the first time I heard that people in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Not long after that , as I passed a station , ...</td>\n",
              "      <td>Not long after, as I passed a train station, I...</td>\n",
              "      <td>Soon after , when I was walking past a train s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>On the platform of the station was the dead bo...</td>\n",
              "      <td>On the station floor lay the dead body of a wo...</td>\n",
              "      <td>A lifeless woman was lying on the ground , whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>But there &amp;apos;s no one to help them , becaus...</td>\n",
              "      <td>But there is no one to help them, because ever...</td>\n",
              "      <td>But nobody helped them , because they were so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>In the mid- &amp;apos; 90s , North Korea experienc...</td>\n",
              "      <td>In the mid-1990s, North Korea experienced a se...</td>\n",
              "      <td>A huge famine hit North Korea in the mid-1990s .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>It caused over a million North Koreans to die ...</td>\n",
              "      <td>It caused more than a million Koreans to starv...</td>\n",
              "      <td>Ultimately , more than a million North Koreans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>The power outages were happening more and more...</td>\n",
              "      <td>Power outages were becoming more and more freq...</td>\n",
              "      <td>Power outages also became more and more freque...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I was wondering all the time why they had elec...</td>\n",
              "      <td>I always wonder why they have electricity and ...</td>\n",
              "      <td>I always wondered why they had lights but we d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>This is a picture from a satellite of North Ko...</td>\n",
              "      <td>This is a satellite image of North Korea at ni...</td>\n",
              "      <td>This is a satellite picture showing North Kore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>This is the Pearl River it &amp;apos;s the natural...</td>\n",
              "      <td>This is the Yalu River, it is the natural bord...</td>\n",
              "      <td>This is the Amrok River , which serves as a pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>It &amp;apos;s possible to see that the river bed ...</td>\n",
              "      <td>It can be seen that the river bed is very narr...</td>\n",
              "      <td>As you can see , the river can be very narrow ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>But so many people died .</td>\n",
              "      <td>But a lot of people died.</td>\n",
              "      <td>But many die .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>And I saw their bodies floating in the river .</td>\n",
              "      <td>And I saw their bodies floating in the river.</td>\n",
              "      <td>Sometimes , I saw dead bodies floating down th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I can &amp;apos;t say specifically how I fled Nort...</td>\n",
              "      <td>I cannot say specifically about how I escaped ...</td>\n",
              "      <td>I can &amp;apos;t reveal many details &amp;#91; about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>At that time , I just thought I was going to h...</td>\n",
              "      <td>At that time, I just thought that I would have...</td>\n",
              "      <td>But I only thought that I would be separated f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>chứ never could I imagine that I would have to...</td>\n",
              "      <td>but never could I have imagined that I would h...</td>\n",
              "      <td>I could have never imagined that it would take...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>In China , it &amp;apos;s very difficult for a gir...</td>\n",
              "      <td>In China, life as a little girl isolated from ...</td>\n",
              "      <td>In China , it was hard living as a young girl ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>I hadn &amp;apos;t imagined what it would be like ...</td>\n",
              "      <td>I could not have imagined what it would be lik...</td>\n",
              "      <td>I had no idea what life was going to be like a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>I have always lived in a constant fear that my...</td>\n",
              "      <td>I live in constant fear that my identity will ...</td>\n",
              "      <td>So I was living in constant fear that my ident...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>One day , that nightmare came true , I was arr...</td>\n",
              "      <td>One day, that nightmare came true, I was arres...</td>\n",
              "      <td>One day , my worst nightmare came true , when ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Somebody informed them that I was North Korean...</td>\n",
              "      <td>Someone told them I was North Korean, so they ...</td>\n",
              "      <td>Someone had accused me of being North Korean ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>I was terrified , and it felt like my heart wa...</td>\n",
              "      <td>I was so scared , and felt like my heart was a...</td>\n",
              "      <td>I was so scared , I thought my heart was going...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>For if as they saw there was anything unnatura...</td>\n",
              "      <td>Because if they see anything unnatural , I wil...</td>\n",
              "      <td>If anything seemed unnatural , I could be impr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>I thought my life coming here was ending , but...</td>\n",
              "      <td>I thought my life was coming to an end, but I ...</td>\n",
              "      <td>I thought my life was over , but I managed to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>After he finished asking , one of the two poli...</td>\n",
              "      <td>After questioning , one of the policemen said ...</td>\n",
              "      <td>After they finished questioning me , one offic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>It &amp;apos;s not North Korean . &amp;quot;</td>\n",
              "      <td>It is not North Korean. \"</td>\n",
              "      <td>She &amp;apos;s not North Korean . &amp;quot;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>And they released me . It was a miracle .</td>\n",
              "      <td>And they let me go. That is a miracle.</td>\n",
              "      <td>And they let me go . It was a miracle .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Some North Koreans in China went to foreign em...</td>\n",
              "      <td>Some North Koreans in China have gone to forei...</td>\n",
              "      <td>Some North Koreans in China seek asylum in for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>these girls were very lucky .</td>\n",
              "      <td>These girls were very lucky.</td>\n",
              "      <td>These girls were so lucky .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>because despite being arrested , learning was ...</td>\n",
              "      <td>because although he was arrested , he was fina...</td>\n",
              "      <td>Even though they were caught , they were event...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>But these North Koreans are not so lucky .</td>\n",
              "      <td>But these North Koreans are not so lucky.</td>\n",
              "      <td>These North Koreans were not so lucky .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Every year , there are countless North Koreans...</td>\n",
              "      <td>Every year, countless North Koreans are arrest...</td>\n",
              "      <td>Every year , countless North Koreans are caugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>While I was very lucky that I was released , s...</td>\n",
              "      <td>While I was very fortunate to have been releas...</td>\n",
              "      <td>Even though I was really fortunate to get out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>The fact that North Koreans had to hide their ...</td>\n",
              "      <td>It is a tragedy that North Koreans have to hid...</td>\n",
              "      <td>It &amp;apos;s tragic that North Koreans have to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Even if they &amp;apos;ve learned Chinese and foun...</td>\n",
              "      <td>Even if they learn Chinese and find a job, the...</td>\n",
              "      <td>Even after learning a new language and getting...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>That &amp;apos;s why after 10 years of hiding my r...</td>\n",
              "      <td>That's why after 10 years of hiding my true id...</td>\n",
              "      <td>That &amp;apos;s why , after 10 years of hiding my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>It &amp;apos;s much more difficult to settle down ...</td>\n",
              "      <td>Settling in here is much more difficult than I...</td>\n",
              "      <td>Settling down in South Korea was a lot more ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Since in South Korea , English is incredibly i...</td>\n",
              "      <td>Because in Korea, English is very important, s...</td>\n",
              "      <td>English was so important in South Korea , so I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>I also realized a huge gap between the South a...</td>\n",
              "      <td>I also realize a huge gap between South and No...</td>\n",
              "      <td>Also , I realized there was a wide gap between...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>We were all North Koreans , but became very di...</td>\n",
              "      <td>We are both Koreans , but have become very dif...</td>\n",
              "      <td>We are all Korean , but inside , we have becom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2d8dedb-24b4-4334-8252-53be0c1a6cd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2d8dedb-24b4-4334-8252-53be0c1a6cd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2d8dedb-24b4-4334-8252-53be0c1a6cd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7af6ca0-2b05-4143-94ad-0956d4c6c86b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7af6ca0-2b05-4143-94ad-0956d4c6c86b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7af6ca0-2b05-4143-94ad-0956d4c6c86b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}